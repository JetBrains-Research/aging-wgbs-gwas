import os
import workflow_util as wu

localrules: all, target, filtered_snv_to_bed, filtered_snv_to_igv_gwas, snv_merged_fln_regions

configfile: "workflow/config.yaml"

assert os.path.exists(config['gwas_table_path']), f"Data file doesn't exist: {config['gwas_table_path']}"
GWAS_DF = wu.load_gwas_data(config['gwas_table_path'])

gwas_filtered_list_path = config['gwas_filtered_list_path'] # generate using: `find filtered_tsv -name '*.tsv' > filtered_tsv.list`
if gwas_filtered_list_path:
    assert os.path.exists(gwas_filtered_list_path), f"GWAS list file doesn't exist: {gwas_filtered_list_path}"
    data_sets = []
    with open(gwas_filtered_list_path) as f:
        data_sets = [s.strip().replace("filtered_tsv/", "").replace(".pval_5e-08.tsv", "") for s in f.readlines()]
    assert data_sets, f"No files were found, seems the list is empty: {gwas_filtered_list_path}"
    print(f"Leaving {len(data_sets)} of {len(GWAS_DF)} GWAS datasets according to list: {gwas_filtered_list_path}")
    GWAS_DF = GWAS_DF.loc[data_sets, :]

rule all:
    input:
        filtered_gwas_snv = lambda wildcards: rules.target.input

rule download_bgz:
    # XXX All *.bgz could be more than 5 TB, maybe is better to make them temporary
    #output: temp("bgz/{gwas_file_id}.tsv.bgz")
    output: "bgz/{gwas_file_id}.tsv.bgz"
    log: "bgz/{gwas_file_id}.tsv.bgz.log"
    params:
        wget_cmd=lambda wildcards: GWAS_DF.loc[wildcards.gwas_file_id, 'wget command'].replace(
            f'-O {wildcards.gwas_file_id}', f'-O bgz/{wildcards.gwas_file_id}'
        )
    shell:
        "{params.wget_cmd} --no-verbose >{log} 2>&1"

rule filter_snv:
    input: rules.download_bgz.output
    output: "filtered_tsv/{gwas_file_id}.pval_{pval_thr}.tsv"
    log: "filtered_tsv/{gwas_file_id}.pval_{pval_thr}.tsv.log"
    conda: "envs/downstream.yaml"
    # pvalue could be also 'NaN', it is processed ok, filtered out by pvalue filter
    shell:
        'bgzip -dc {input} | awk \'function assert(cond, errormsg)'
        '{{ if (!cond) {{ print "Assertion failed"; exit 1}} }}; '
        '{{ if (NR == 1) {{ assert($NF == "pval") }}; if (NR == 1 || $NF < 0.00000005) print }}\''
        ' > {output} 2>{log}'

rule filtered_snv_to_bed:
    input: rules.filter_snv.output
    output: "filtered_bed/{gwas_file_id}.pval_{pval_thr}.snv.bed"
    log: "filtered_bed/{gwas_file_id}.pval_{pval_thr}.snv.bed.log"
    # snv file could have several alternatives for the same position, here we need to count it only once
    # => apply 'uniq'
    shell:
        "awk -v FS=':' -v OFS='\t' '{{ if (NR != 1) print $1,$2,$2+1 }}' {input} | uniq > {output} 2>{log}"

rule filtered_snv_to_igv_gwas:
    input: rules.filter_snv.output
    output: "filtered_igv_track/{gwas_file_id}.pval_{pval_thr}.snv.gwas"
    log: "filtered_igv_track/{gwas_file_id}.pval_{pval_thr}.snv.gwas.log"
    # NB: snv file could have several alternatives for the same position
    shell:
        # leave 1st (chr:pos:..) and last (pvalue) fields. Pvalue is always last one, could be 11-th or 12-th column
        "cat {input} | awk '{{ print $1\":\"$NF}}' | awk -v FS=':' -v OFS='\t' '{{ if ($5 == 0.0) {{ $5=1e-300 }}; if (NR==1) print \"chr\tpos\tsnp\tp\"; else print $1,$2,$1\":\"$2\":\"$3\":\"$4,$5} }}' | uniq > {output} 2>{log}"


rule target:
    input:
        expand(
            [
                str(rules.filter_snv.output),
                str(rules.filtered_snv_to_bed.output),
                str(rules.filtered_snv_to_igv_gwas.output),

                # Optional:
                *([] if gwas_filtered_list_path else str(rules.download_bgz.output))  # optional GWAS raw data
            ],
            pval_thr=config['gwas_snp_filter_pvalue_thr'],
            gwas_file_id=GWAS_DF['gwas_file_id'],
            genome='hs37d5'
        )

# TODO 1: gwas enrichment at dmrs
# TODO 2: influencing dmrs


